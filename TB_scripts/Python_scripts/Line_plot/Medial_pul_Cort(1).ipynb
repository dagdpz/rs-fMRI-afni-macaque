{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9ac06f-6777-4d40-a3c3-bc5e6612d828",
   "metadata": {},
   "source": [
    "### I did not intend to display the results; therefore, it says that errors occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4556ca-63a4-48b8-8823-8573a32f0739",
   "metadata": {},
   "source": [
    "## 1. left medial Pulvinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc61d203-e858-4ff7-8e3a-a1b40090449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# List of subjects and prefix numbers\n",
    "subjects = ['Linus', 'Curius', 'Linus1015', 'Pinocchio', 'Rio']  \n",
    "prefix_numbers = ['002']  \n",
    "\n",
    "# Iterate over each subject and prefix number\n",
    "for subject in subjects:\n",
    "    for prefix_number in prefix_numbers:\n",
    "        \n",
    "        # Load predrug CSV file\n",
    "        predrug_file = f'netts/csv_files/long_correlation_matrix_{subject}_predrug_{prefix_number}.csv'\n",
    "        \n",
    "        if not os.path.exists(predrug_file):\n",
    "            print(f\"File for {subject} with prefix {prefix_number} not found. Skipping it...\")\n",
    "            continue\n",
    "        \n",
    "        df_predrug = pd.read_csv(predrug_file)\n",
    "        \n",
    "        # Dictionary to store mean values\n",
    "        mean_values = {}\n",
    "        \n",
    "        for hemisphere in ['left', 'right']:\n",
    "            prefix2 = 'CR_' if hemisphere == 'right' else 'CL_'\n",
    "            \n",
    "            # Filter DataFrame\n",
    "            df_filtered = df_predrug[\n",
    "                df_predrug['Variable1'].str.startswith('SL') &\n",
    "                df_predrug['Variable1'].str.contains('MPul') &\n",
    "                df_predrug['Variable2'].str.startswith(prefix2) &\n",
    "                (df_predrug['Correlation'] != 1)\n",
    "            ]\n",
    "            \n",
    "            # Calculate mean correlation\n",
    "            mean_correlation = df_filtered['Correlation'].mean()\n",
    "            mean_values[hemisphere] = mean_correlation\n",
    "        \n",
    "        # Print results\n",
    "        #print(f\"Mean correlations for {subject} with prefix {prefix_number} (only predrug):\")\n",
    "        #print(f\"Left Hemisphere: {mean_values['left']:.4f}\")\n",
    "        #print(f\"Right hemisphere: {mean_values['right']:.4f}\")\n",
    "        #print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc412e4-c013-4261-b2cb-8498d88ced0a",
   "metadata": {},
   "source": [
    "## 2. right medial Pul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c535c2ae-74e4-4c69-bc57-b0faa85b30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# List of subjects and prefix numbers\n",
    "subjects = ['Linus', 'Curius', 'Linus1015', 'Pinocchio', 'Rio']  \n",
    "prefix_numbers = ['002']  \n",
    "\n",
    "# Iterate over each subject and prefix number\n",
    "for subject in subjects:\n",
    "    for prefix_number in prefix_numbers:\n",
    "        \n",
    "        # Load predrug CSV file\n",
    "        predrug_file = f'netts/csv_files/long_correlation_matrix_{subject}_predrug_{prefix_number}.csv'\n",
    "        \n",
    "        if not os.path.exists(predrug_file):\n",
    "            print(f\"File for {subject} with prefix {prefix_number} not found. Skipping it...\")\n",
    "            continue\n",
    "        \n",
    "        df_predrug = pd.read_csv(predrug_file)\n",
    "        \n",
    "        # Dictionary to store mean values\n",
    "        mean_values = {}\n",
    "        \n",
    "        for hemisphere in ['left', 'right']:\n",
    "            prefix2 = 'CR_' if hemisphere == 'right' else 'CL_'\n",
    "            \n",
    "            # Filter DataFrame\n",
    "            df_filtered = df_predrug[\n",
    "                df_predrug['Variable1'].str.startswith('SR') &\n",
    "                df_predrug['Variable1'].str.contains('MPul') &\n",
    "                df_predrug['Variable2'].str.startswith(prefix2) &\n",
    "                (df_predrug['Correlation'] != 1)\n",
    "            ]\n",
    "            \n",
    "            # Calculate mean correlation\n",
    "            mean_correlation = df_filtered['Correlation'].mean()\n",
    "            mean_values[hemisphere] = mean_correlation\n",
    "        \n",
    "        # Print results\n",
    "        #print(f\"Mean correlations for {subject} with prefix {prefix_number} (only predrug):\")\n",
    "        #print(f\"Left hemisphere: {mean_values['left']:.4f}\")\n",
    "        #print(f\"Right hemisphere: {mean_values['right']:.4f}\")\n",
    "        #print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce38792-a117-4bd6-b4f7-79baa3ab642d",
   "metadata": {},
   "source": [
    "# Statistic and data sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884f0e3c-9f25-4d15-8b59-27cec8f0e657",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 78 (1246065783.py, line 81)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 81\u001b[0;36m\u001b[0m\n\u001b[0;31m    if df_corr_clean.shape[0] >= 3:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# Subjekte und Präfixe\n",
    "subjects = ['Linus', 'Curius', 'Linus1015', 'Pinocchio', 'Rio']\n",
    "prefix_numbers = ['002']\n",
    "\n",
    "# Ergebnisse sammeln\n",
    "data = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for prefix_number in prefix_numbers:\n",
    "        file_path = f'netts/csv_files/long_correlation_matrix_{subject}_predrug_{prefix_number}.csv'\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path} — will be skipped.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        entry = {'subject': subject}\n",
    "\n",
    "        def safe_mean(label, df_filtered):\n",
    "            if df_filtered.empty:\n",
    "                print(f\"Warning: No data for {subject} – {label}\")\n",
    "                return float('nan')\n",
    "            mean_val = df_filtered['Correlation'].mean()\n",
    "            if pd.isna(mean_val):\n",
    "                print(f\"Warning: Mean is NaN for {subject} – {label}\")\n",
    "            elif len(df_filtered) < 3:\n",
    "                print(f\"Attention: Only {len(df_filtered)} values for {subject} – {label}\")\n",
    "            return mean_val\n",
    "\n",
    "        # Left Intra (SL → CL_)\n",
    "        df_li = df[\n",
    "            df['Variable1'].str.contains('SL') &\n",
    "            df['Variable1'].str.contains('MPul') &\n",
    "            df['Variable2'].str.startswith('CL_') &\n",
    "            (df['Correlation'] != 1)\n",
    "        ]\n",
    "        entry['left_intra'] = safe_mean(\"left_intra (SL→CL_)\", df_li)\n",
    "\n",
    "        # Left Inter (SL → CR_)\n",
    "        df_le = df[\n",
    "            df['Variable1'].str.contains('SL') &\n",
    "            df['Variable1'].str.contains('MPul') &\n",
    "            df['Variable2'].str.startswith('CR_') &\n",
    "            (df['Correlation'] != 1)\n",
    "        ]\n",
    "        entry['left_inter'] = safe_mean(\"left_inter (SL→CR_)\", df_le)\n",
    "\n",
    "        # Right Intra (SR → CR_)\n",
    "        df_ri = df[\n",
    "            df['Variable1'].str.contains('SR') &\n",
    "            df['Variable1'].str.contains('MPul') &\n",
    "            df['Variable2'].str.startswith('CR_') &\n",
    "            (df['Correlation'] != 1)\n",
    "        ]\n",
    "        entry['right_intra'] = safe_mean(\"right_intra (SR→CR_)\", df_ri)\n",
    "\n",
    "        # Right Inter (SR → CL_)\n",
    "        df_re = df[\n",
    "            df['Variable1'].str.contains('SR') &\n",
    "            df['Variable1'].str.contains('MPul') &\n",
    "            df['Variable2'].str.startswith('CL_') &\n",
    "            (df['Correlation'] != 1)\n",
    "        ]\n",
    "        entry['right_inter'] = safe_mean(\"right_inter (SR→CL_)\", df_re)\n",
    "\n",
    "        data.append(entry)\n",
    "\n",
    "# Convert into dataframe\n",
    "df_corr = pd.DataFrame(data)\n",
    "print(\"\\n=== Mittelwerte pro Subjekt ===\")\n",
    "print(df_corr)\n",
    "\n",
    "df_corr_clean = df_corr.dropna(subset=['left_intra', 'left_inter', 'right_intra', 'right_inter'])\n",
    "if df_corr_clean.shape[0] < len(subjects):\n",
    "    #print(f\"\\n  {len(subjects) - df_corr_clean.shape[0]} Subjects were excluded due to missing values.\")\n",
    "\n",
    "if df_corr_clean.shape[0] >= 3:\n",
    "    print(\"\\n=== Friedman-Test: All 4 conditions ===\")\n",
    "    stat, p = friedmanchisquare(\n",
    "        df_corr_clean['left_intra'],\n",
    "        df_corr_clean['left_inter'],\n",
    "        df_corr_clean['right_intra'],\n",
    "        df_corr_clean['right_inter']\n",
    "    )\n",
    "    #print(f\"Test statistic = {stat:.4f}, p-Wert = {p:.4f}\")\n",
    "else:\n",
    "    #print(\"\\n Too few valid subjects for the Friedman test (at least 3 subjects with complete data are required).\")\n",
    "\n",
    "    # Wilcoxon signed-rank tests for the desired pairs\n",
    "    print(\"\\n=== Wilcoxon signed-rank test: pairwise comparisons ===\")\n",
    "    \n",
    "    # Left Intra vs Left Inter\n",
    "    data_li = df_corr_clean['left_intra']\n",
    "    data_le = df_corr_clean['left_inter']\n",
    "    \n",
    "    if len(data_li) > 1 and len(data_le) > 1:\n",
    "        stat, p = wilcoxon(data_li, data_le)\n",
    "        #print(f\"left_intra vs left_inter: Teststatistik = {stat:.4f}, p-Wert = {p:.4f}\")\n",
    "    else:\n",
    "        #print(f\"left_intra vs left_inter: Too little data for the Wilcoxon test\")\n",
    "\n",
    "    # Right Intra vs Right Inter\n",
    "    data_ri = df_corr_clean['right_intra']\n",
    "    data_re = df_corr_clean['right_inter']\n",
    "    \n",
    "    if len(data_ri) > 1 and len(data_re) > 1:\n",
    "        stat, p = wilcoxon(data_ri, data_re)\n",
    "        #print(f\"right_intra vs right_inter: Teststatistik = {stat:.4f}, p-Wert = {p:.4f}\")\n",
    "    else:\n",
    "        #print(f\"right_intra vs right_inter: Too little data for the Wilcoxon test\")\n",
    "\n",
    "else:\n",
    "   # print(\"\\n Too few valid subjects for the Friedman test (at least 3 subjects with complete data are required).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed9324-82bb-48e1-aa26-1cfdd7e6747b",
   "metadata": {},
   "source": [
    "# Generating Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9daf85b9-4c5f-4576-93d7-9ccd705c5018",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_corr_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Data for Left\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m subjects \u001b[38;5;241m=\u001b[39m \u001b[43mdf_corr_clean\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      6\u001b[0m left_intra \u001b[38;5;241m=\u001b[39m df_corr_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_intra\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      7\u001b[0m left_inter \u001b[38;5;241m=\u001b[39m df_corr_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_inter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_corr_clean' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for Left\n",
    "subjects = df_corr_clean['subject'].values\n",
    "left_intra = df_corr_clean['left_intra'].values\n",
    "left_inter = df_corr_clean['left_inter'].values\n",
    "\n",
    "# Data for Right\n",
    "right_intra = df_corr_clean['right_intra'].values\n",
    "right_inter = df_corr_clean['right_inter'].values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 5), sharey=True)\n",
    "\n",
    "x_pos = [0, 1]  \n",
    "\n",
    "# Left Plot\n",
    "for i in range(len(subjects)):\n",
    "    label = \"Individual results\" if i == 0 else None\n",
    "    axs[0].plot(x_pos, [left_intra[i], left_inter[i]], marker='o', color='gray', alpha=0.6, label=label)\n",
    "\n",
    "# Means (Left) - Rot\n",
    "mean_left_intra = np.nanmean(left_intra)\n",
    "mean_left_inter = np.nanmean(left_inter)\n",
    "axs[0].plot(x_pos, [mean_left_intra, mean_left_inter], color='red', marker='D', markersize=6, linewidth=2, label='Mean')\n",
    "axs[0].legend(loc='lower left', bbox_to_anchor=(0.0, 0.0), frameon=True)\n",
    "\n",
    "axs[0].set_title('Medial pulvinar, left hemisphere')\n",
    "axs[0].set_xticks(x_pos)\n",
    "axs[0].set_xticklabels(['Intra', 'Inter'])\n",
    "axs[0].set_ylabel('Mean correlation')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Right Plot\n",
    "for i in range(len(subjects)):\n",
    "    label = \"Individual results\" if i == 0 else None\n",
    "    axs[1].plot(x_pos, [right_intra[i], right_inter[i]], marker='o', color='gray', alpha=0.6, label=label)\n",
    "axs[1].set_title('Medial pulvinar , right hemisphere')\n",
    "axs[1].set_xticks(x_pos)\n",
    "axs[1].set_xticklabels(['Intra', 'Inter'])\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Means (Right) - Rot\n",
    "mean_right_intra = np.nanmean(right_intra)\n",
    "mean_right_inter = np.nanmean(right_inter)\n",
    "axs[1].plot(x_pos, [mean_right_intra, mean_right_inter], color='red', marker='D', markersize=6, linewidth=2, label='Mean')\n",
    "axs[1].legend()\n",
    "\n",
    "#plt.suptitle('Intra vs. Inter Correlation for each pulvinar')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"medial_Pul_comparison_cortex.png\", dpi=300)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6be98-db31-4159-b46d-180a7757f91a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
